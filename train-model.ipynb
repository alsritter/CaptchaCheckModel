{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA (GPU support) is available and PyTorch can use GPUs!\n",
      "Epoch 1, LR: 0.01\n",
      "Epoch 1, Loss: 17.201837640778724, Accuracy: 3.34%\n",
      "Epoch 2, LR: 0.01\n",
      "Epoch 2, Loss: 16.1670816807715, Accuracy: 3.34%\n",
      "Epoch 3, LR: 0.01\n",
      "Epoch 3, Loss: 16.16414883803957, Accuracy: 3.35%\n",
      "Epoch 4, LR: 0.01\n",
      "Epoch 4, Loss: 16.16407837999812, Accuracy: 3.29%\n",
      "Epoch 5, LR: 0.01\n",
      "Epoch 5, Loss: 16.163849411630128, Accuracy: 3.39%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\33204\\Documents\\project\\alsritter.icu\\st-pytorch\\train-model.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=227'>228</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=229'>230</a>\u001b[0m \u001b[39m# 训练模型\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=230'>231</a>\u001b[0m train_losses \u001b[39m=\u001b[39m train_model(\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=231'>232</a>\u001b[0m     model, trainloader, criterion, optimizer, epochs, device)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=233'>234</a>\u001b[0m \u001b[39m# 测试模型\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=234'>235</a>\u001b[0m test_accuracies \u001b[39m=\u001b[39m [test_model(model, testloader, device)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=235'>236</a>\u001b[0m                    \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs)]\n",
      "\u001b[1;32mc:\\Users\\33204\\Documents\\project\\alsritter.icu\\st-pytorch\\train-model.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# 记录这个周期中正确预测的字符数量\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m    \u001b[39m# 记录这个周期中总的字符数量\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m \u001b[39mfor\u001b[39;49;00m _, data \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trainloader, \u001b[39m0\u001b[39;49m):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m     inputs, labels \u001b[39m=\u001b[39;49m data[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device), data[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=141'>142</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\33204\\Documents\\project\\alsritter.icu\\st-pytorch\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\33204\\Documents\\project\\alsritter.icu\\st-pytorch\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\33204\\Documents\\project\\alsritter.icu\\st-pytorch\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\33204\\Documents\\project\\alsritter.icu\\st-pytorch\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32mc:\\Users\\33204\\Documents\\project\\alsritter.icu\\st-pytorch\\train-model.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m label \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([char_to_int[char]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m                      \u001b[39mfor\u001b[39;00m char \u001b[39min\u001b[39;00m label_str], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)  \u001b[39m# 转换为整数张量（就是取得当前这个 char 在字符串的索引）\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(image)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m# label: 是一个一维张量，维度为 [sequence_length]，其中 sequence_length 是字符序列的长度。每个元素是一个类别标签（索引）。\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39mreturn\u001b[39;00m image, label\n",
      "File \u001b[1;32mc:\\Users\\33204\\Documents\\project\\alsritter.icu\\st-pytorch\\.venv\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\33204\\Documents\\project\\alsritter.icu\\st-pytorch\\.venv\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:486\u001b[0m, in \u001b[0;36mLambda.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m--> 486\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlambd(img)\n",
      "\u001b[1;32mc:\\Users\\33204\\Documents\\project\\alsritter.icu\\st-pytorch\\train-model.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m pad_h \u001b[39m=\u001b[39m (max_dim \u001b[39m-\u001b[39m h) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# 返回填充后的图像\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/33204/Documents/project/alsritter.icu/st-pytorch/train-model.ipynb#W0sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mreturn\u001b[39;00m transforms\u001b[39m.\u001b[39;49mPad((pad_w, pad_h))(img)\n",
      "File \u001b[1;32mc:\\Users\\33204\\Documents\\project\\alsritter.icu\\st-pytorch\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\33204\\Documents\\project\\alsritter.icu\\st-pytorch\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\33204\\Documents\\project\\alsritter.icu\\st-pytorch\\.venv\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:466\u001b[0m, in \u001b[0;36mPad.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m    459\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \u001b[39m        img (PIL Image or Tensor): Image to be padded.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[39m        PIL Image or Tensor: Padded image.\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mpad(img, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfill, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_mode)\n",
      "File \u001b[1;32mc:\\Users\\33204\\Documents\\project\\alsritter.icu\\st-pytorch\\.venv\\Lib\\site-packages\\torchvision\\transforms\\functional.py:539\u001b[0m, in \u001b[0;36mpad\u001b[1;34m(img, padding, fill, padding_mode)\u001b[0m\n\u001b[0;32m    537\u001b[0m     _log_api_usage_once(pad)\n\u001b[0;32m    538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> 539\u001b[0m     \u001b[39mreturn\u001b[39;00m F_pil\u001b[39m.\u001b[39;49mpad(img, padding\u001b[39m=\u001b[39;49mpadding, fill\u001b[39m=\u001b[39;49mfill, padding_mode\u001b[39m=\u001b[39;49mpadding_mode)\n\u001b[0;32m    541\u001b[0m \u001b[39mreturn\u001b[39;00m F_t\u001b[39m.\u001b[39mpad(img, padding\u001b[39m=\u001b[39mpadding, fill\u001b[39m=\u001b[39mfill, padding_mode\u001b[39m=\u001b[39mpadding_mode)\n",
      "File \u001b[1;32mc:\\Users\\33204\\Documents\\project\\alsritter.icu\\st-pytorch\\.venv\\Lib\\site-packages\\torchvision\\transforms\\_functional_pil.py:182\u001b[0m, in \u001b[0;36mpad\u001b[1;34m(img, padding, fill, padding_mode)\u001b[0m\n\u001b[0;32m    179\u001b[0m         image\u001b[39m.\u001b[39mputpalette(palette)\n\u001b[0;32m    180\u001b[0m         \u001b[39mreturn\u001b[39;00m image\n\u001b[1;32m--> 182\u001b[0m     \u001b[39mreturn\u001b[39;00m ImageOps\u001b[39m.\u001b[39;49mexpand(img, border\u001b[39m=\u001b[39;49mpadding, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mopts)\n\u001b[0;32m    183\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(padding, \u001b[39mint\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\33204\\Documents\\project\\alsritter.icu\\st-pytorch\\.venv\\Lib\\site-packages\\PIL\\ImageOps.py:411\u001b[0m, in \u001b[0;36mexpand\u001b[1;34m(image, border, fill)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     palette \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 411\u001b[0m out \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mnew(image\u001b[39m.\u001b[39;49mmode, (width, height), color)\n\u001b[0;32m    412\u001b[0m \u001b[39mif\u001b[39;00m palette:\n\u001b[0;32m    413\u001b[0m     out\u001b[39m.\u001b[39mputpalette(palette\u001b[39m.\u001b[39mpalette)\n",
      "File \u001b[1;32mc:\\Users\\33204\\Documents\\project\\alsritter.icu\\st-pytorch\\.venv\\Lib\\site-packages\\PIL\\Image.py:2914\u001b[0m, in \u001b[0;36mnew\u001b[1;34m(mode, size, color)\u001b[0m\n\u001b[0;32m   2912\u001b[0m     im\u001b[39m.\u001b[39mpalette \u001b[39m=\u001b[39m ImagePalette\u001b[39m.\u001b[39mImagePalette()\n\u001b[0;32m   2913\u001b[0m     color \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39mpalette\u001b[39m.\u001b[39mgetcolor(color)\n\u001b[1;32m-> 2914\u001b[0m \u001b[39mreturn\u001b[39;00m im\u001b[39m.\u001b[39m_new(core\u001b[39m.\u001b[39;49mfill(mode, size, color))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA (GPU support) is available and PyTorch can use GPUs!\")\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch will use CPU.\")\n",
    "\n",
    "# 检查 CUDA 是否可用并定义设备\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def pad_to_square(img):\n",
    "    # 获取图像的尺寸\n",
    "    w, h = img.size\n",
    "    # 计算要填充的最大边\n",
    "    max_dim = max(w, h)\n",
    "    # 计算左右和上下需要填充的尺寸\n",
    "    pad_w = (max_dim - w) // 2\n",
    "    pad_h = (max_dim - h) // 2\n",
    "    # 返回填充后的图像\n",
    "    return transforms.Pad((pad_w, pad_h))(img)\n",
    "\n",
    "\n",
    "# 数据加载和预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x.convert(\"RGB\")),  # 转换为RGB格式\n",
    "    transforms.Lambda(pad_to_square),                # 将图像填充为正方形\n",
    "    transforms.Resize((128, 128)),                   # 将图像调整为所需尺寸\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 定义分类\n",
    "nums = list(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\")\n",
    "\n",
    "\n",
    "# 创建字符到整数的映射\n",
    "char_to_int = {char: i for i, char in enumerate(nums)}\n",
    "\n",
    "\n",
    "class CaptchaDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(\n",
    "            root_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        image = Image.open(img_name)\n",
    "        label_str = self.image_files[idx].split('_')[1].split('.')[\n",
    "            0]  # 提取验证码的名称作为 Label\n",
    "        label = torch.tensor([char_to_int[char]\n",
    "                             for char in label_str], dtype=torch.long)  # 转换为整数张量（就是取得当前这个 char 在字符串的索引）\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        # label: 是一个一维张量，维度为 [sequence_length]，其中 sequence_length 是字符序列的长度。每个元素是一个类别标签（索引）。\n",
    "        return image, label\n",
    "\n",
    "\n",
    "train_dataset = CaptchaDataset(root_dir='captcha', transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = CaptchaDataset(root_dir='test_captcha', transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "class CaptchaModel(nn.Module):\n",
    "    def __init__(self, num_chars):\n",
    "        \"\"\"验证码识别模型\n",
    "\n",
    "        Args:\n",
    "            num_chars (int): 字符类别的数量\n",
    "        \"\"\"\n",
    "        super(CaptchaModel, self).__init__()\n",
    "\n",
    "        # 假设验证码由4个字符组成\n",
    "        self.num_chars = num_chars\n",
    "        # 输入的是 3 维的图像，输出的是 32 维的特征图\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # 对于 128x128 输入，经过4次下采样后，尺寸将变为 8x8\n",
    "        self.fc1 = nn.Linear(256 * 8 * 8, 1024)\n",
    "        # 输出层，把 1024 维的特征转换为 4 * num_chars 维\n",
    "        self.fc2 = nn.Linear(1024, self.num_chars*4)  # 4 是验证码包含的字符数\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "\n",
    "        x = x.view(-1, 256 * 8 * 8)\n",
    "\n",
    "        # 全连接层\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x.view(x.size(0), 4, self.num_chars)\n",
    "\n",
    "\n",
    "model = CaptchaModel(len(nums)).to(device)\n",
    "\n",
    "# 创建一个 SummaryWriter 对象\n",
    "writer = SummaryWriter('runs/captcha_training')\n",
    "\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# 定义StepLR调度器，每10个epoch，学习率乘以gamma=0.9\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "\n",
    "\n",
    "def train_model(model, trainloader, criterion, optimizer, epochs, device):\n",
    "    train_losses = []\n",
    "    train_accuracies = []  # 用于记录每个周期的准确率\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0  # 记录这个周期中正确预测的字符数量\n",
    "        total = 0    # 记录这个周期中总的字符数量\n",
    "\n",
    "        for _, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            # outputs 的维度是 [batch_size, sequence_length, num_chars]\n",
    "            # labels 的维度是 [batch_size, sequence_length]\n",
    "            # outputs[:, i, :]：此操作从 outputs 张量中选取第 i 个字符的预测，对于批次中的所有样本。\n",
    "            #                   其维度为 [batch_size, num_chars]，表示每个样本的第 i 个字符的类别预测分数。\n",
    "            # labels[:, i]：此操作从 labels 张量中选取第 i 个字符的实际类别标签，对于批次中的所有样本。\n",
    "            #               其维度为 [batch_size]，表示每个样本的第 i 个字符的实际类别。\n",
    "            #\n",
    "            # 通过遍历 sequence_length，我们可以为每个字符位置计算损失。\n",
    "            loss = sum([criterion(outputs[:, i, :], labels[:, i])\n",
    "                       for i in range(labels.size(1))])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # 计算这个批次的准确率\n",
    "            _, predicted = torch.max(outputs.data, 2)\n",
    "            total += labels.size(0) * labels.size(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # 每个epoch结束后，调用scheduler的step方法来更新学习率\n",
    "        scheduler.step()\n",
    "        # 打印当前学习率\n",
    "        print(f\"Epoch {epoch+1}, LR: {scheduler.get_last_lr()[0]}\")\n",
    "\n",
    "        epoch_loss = running_loss / len(trainloader)\n",
    "        epoch_accuracy = 100 * correct / total  # 计算这个周期的准确率\n",
    "\n",
    "        # 使用 SummaryWriter 记录损失和准确率\n",
    "        writer.add_scalar('Training Loss', epoch_loss, epoch)\n",
    "        writer.add_scalar('Training Accuracy', epoch_accuracy, epoch)\n",
    "\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_accuracy)  # 将这个周期的准确率添加到列表中\n",
    "\n",
    "        # 打印日志，不再更新图表\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}, Loss: {epoch_loss}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "    return train_losses\n",
    "\n",
    "\n",
    "def test_model(model, testloader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            # torch.max 函数用于返回指定维度上的最大值。\n",
    "            # 在这里，我们希望得到每个验证码字符位置的最大分数对应的字符类别的索引。\n",
    "            # 因为 outputs 的形状是 [batch_size, sequence_length, num_chars]，我们沿着第 2 个维度（索引为2）取最大值，这样我们可以为每个样本的每个字符位置得到一个最大分数的索引。\n",
    "            _, predicted = torch.max(outputs.data, 2)\n",
    "\n",
    "            # 因为 labels 的维度是 [batch_size, sequence_length]\n",
    "            # 这一行代码计算了总的字符数量。labels.size(0) 是批次中的样本数，而 labels.size(1) 是每个验证码的字符长度。\n",
    "            # 所以，两者的乘积给出了这个批次中所有验证码字符的总数。\n",
    "            total += labels.size(0) * labels.size(1)\n",
    "\n",
    "            # predicted == labels 返回一个布尔值的张量，形状与 labels 相同。如果预测正确，对应位置的值为 True，否则为 False。\n",
    "            # .sum() 计算这个批次中正确预测的字符数量。\n",
    "            # .item() 方法将单元素张量的值转换为 Python 数值。\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "\n",
    "def plot_training(train_losses, test_accuracies):\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Train Loss', color=color)\n",
    "    ax1.plot(train_losses, color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('Test Accuracy', color=color)\n",
    "    ax2.plot(test_accuracies, color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "# 训练模型\n",
    "train_losses = train_model(\n",
    "    model, trainloader, criterion, optimizer, epochs, device)\n",
    "\n",
    "# 测试模型\n",
    "test_accuracies = [test_model(model, testloader, device)\n",
    "                   for _ in range(epochs)]\n",
    "\n",
    "# 绘制训练损失和测试精度\n",
    "plot_training(train_losses, test_accuracies)\n",
    "\n",
    "\n",
    "print(\"Finished Training\")\n",
    "\n",
    "# 评估模型\n",
    "test_accuracy = test_model(model, testloader, device)\n",
    "print(f\"Accuracy on test set: {test_accuracy}%\")\n",
    "\n",
    "\n",
    "writer.close()\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'captcha_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
